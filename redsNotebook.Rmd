---
title: "Reds Notebook"
author: "Harrison Cradduck, Joey Endres, Will Paz"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

> This notebook is designed to detail the processes in which we wrangled the data given to us in kaggle, we fitted and selected various models, we validated said models, and we chose our final model for submission. We were tasked with the question of predicting a Cincinnati Reds' player's total playing time in the 2024 season using play-by-play data from 2021, 2022, and 2023. The sections below aim to display and thoughts and ideas on how we should go about cleaning the data, organizing the data, fitting an appropriate and insightful model, and implementing it for our final submission.

## Data Wrangling

> Our initial approach to the data was organizing both the savant and lahman data to be specific to batters and pitchers separately. This allowed us to create two comprehensive dataframes of every variable we deemed "possibly relevant" to predicting a batter or pitchers playing time (playing time being measured in plate appearances for batters and at bats faced for pitchers). Creating these lists involved pivoting variables like type of pitch, play event, and how the ball was hit into their separate categorical values to be treated independently within a regression model. Then depending on the type of variable, we created either averages (ex. launch speed, hit distance) or totals (ex. singles, field outs) for a player by at bat, then by game, then by season, and ultimately in total; a weighted average was implemented based on total plate appearances or batters faced in a game and season. Once these lists were complete, we combined them into one dataframe for all players, making the disinction between shared variables (ex. total singles hit batting vs. total singles allowed pitching) for players that played both sides of the ball at one point or another. One thing that was taken into consideration for ensuring the best data was being used for predictions was removing pitchers that batted at some point in the 2021-2023 seasons other than Shohei Ohtani, as pitchers very rarely bat after the conclusion of the 2021 season, and we want our data to be fitted to the same constraints imposed on the 2024 season.

## Regression Modeling

> Will, this is the outline I'm thinking of for this section and the selection/validation section below: discuss train/test split, then fitting full regression model, then using forward/backward/stepwise AIC/BIC, comparing them, finding backwardAIC was best by multiple metrics, then improving upon it by eliminating high VIFs and/or high insignificance and ultimately landing on performing stepwiseBIC on the backwardAIC with k-folds validation, then removing contextually insignficant variables and looking at diagnostics to confirm the final "best" model. EMPHASIZE ONLY 10 VARIABLES IN MODEL

> When approaching this questions, we decided to go with a traditional statistical approach to model building. Our first step was to split our data into a training and testing split, where we chose a 80/20 split. Then using our training data, we started with fitting a full regression model to create a baseline model. Obviously, the entire model predicts the data well, but as with most statistical models, we want to find the simplest model that performs well by satisfying basic statistical modeling practices. We began to pick the best model by using all combinations of forward, backward, and stepwise selection by AIC and BIC comparison and comparing their quantative results to one another. We found that the backwards variable selection using AIC was by far the best choice using various metrics. 

> Then afterwards, we decided to remove insignificant variables of our new model by applying the stepwise selection based on BIC on our backwards AIC model with k-fold validation to ensure we found the simplest and signficant model. After that we wanted to removed multicolinearity in our model since the multicolinearity assumption in our model could not be accepted, so we checked the VIF of each variable and found a reasonable threshold to remove variables. Lastly, we removed any conextual outliers that would not accurately represent the prediction of playing time in a vacuum of baseball. We landed on a model that consists of 10 variables, for which the model can reasonably accept the normality, multicolinearity, constant variance, and independence assumptions.

> What makes this model different than the others are the fact that we have 10 variables in our model, all of which allow for no violations of any assumption as well as use variables that are not other variations of playing time. The way we think of it, if we have two models side to side with one that performs slightly better than the other and one consists of less predictors and less contextually similar variables, we would choose the latter. The fact that we could have predicted play time using something similar to Average AB/Game or a contextually similar predictor to the response and didn't, is what we believe makes our model unique and meaningful when predicting play time in a vacuum. Our objective was to predict playing time without using playing time as a predictor, and our model reflects just that.


## Model Selection & Validation

> 

## Findings

> discuss the variables in our final model (total_strikeout_batted, weighted_avg_max_pitches_thrown_pitched, weighted_avg_max_times_faced_batted, total_walk_pitched, total_single_pitched, total_single_batted, weighted_avg_iso_value_batted, total_walk_batted, weighted_avg_delta_run_exp_pitched, total_at_bats_faced_as_reliever_pitched), discuss the specific graphs below. EMPHASIZE ONLY 10 VARIABLES IN MODEL

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(patchwork)

allPlayersDataallallall <- read.csv("allPlayersDataallallall.csv", header=TRUE)

selectedVars <- allPlayersDataallallall %>% 
  dplyr::select(AVG_PLAYING_TIME, plateAppearances_batted, atBatsFaced_pitched, weighted_avg_iso_value_batted, total_single_batted, weighted_avg_max_times_faced_batted, weighted_avg_max_pitches_thrown_pitched, total_walk_batted, total_strikeout_batted, total_at_bats_faced_as_starter_pitched, total_at_bats_faced_as_reliever_pitched)
```

```{r, fig.width=10, fig.height=5, echo=FALSE, message=FALSE}
batting <- selectedVars %>% 
  filter(plateAppearances_batted > atBatsFaced_pitched & plateAppearances_batted > 100) %>% 
  mutate(avg_single_batted = total_single_batted / ((atBatsFaced_pitched + plateAppearances_batted)/AVG_PLAYING_TIME))

plot1 <- ggplot(batting, aes(x = avg_single_batted, y = AVG_PLAYING_TIME)) +
  geom_point(alpha = 0.6) +  
  geom_smooth(method="lm", color="blue", se=FALSE) +
  labs(title = "Playing Time vs. Total Singles Batted",
       x = "Total Singles Batted",
       y = "Playing Time") +
  theme_minimal()

plot2 <- ggplot(batting, aes(x = weighted_avg_iso_value_batted, y = AVG_PLAYING_TIME)) +
  geom_point(alpha = 0.6) +  
  geom_smooth(method="lm", color="blue", se=FALSE) +
  labs(title = "Playing Time vs. Average ISO Value",
       x = "Average ISO Value",
       y = "Playing Time") +
  theme_minimal()

plot1 + plot2
```

```{r, fig.width=10, fig.height=5, echo=FALSE, message=FALSE}
pitching <- selectedVars %>% 
  filter(plateAppearances_batted >100) %>%
  mutate(avg_walk_batted = total_walk_batted / ((atBatsFaced_pitched + plateAppearances_batted)/AVG_PLAYING_TIME),
         avg_strikeout_batted = total_strikeout_batted / ((atBatsFaced_pitched + plateAppearances_batted)/AVG_PLAYING_TIME))

plot3 <- ggplot(pitching, aes(x = avg_walk_batted, y = AVG_PLAYING_TIME)) +
  geom_point(alpha = 0.6) +  
  geom_smooth(method="lm", color="blue", se=FALSE) +
  labs(title = "Playing Time vs. Avg Walks Batted",
       x = "Average Walks Batted",
       y = "Playing Time") +
  theme_minimal()

plot4 <- ggplot(pitching, aes(x = avg_strikeout_batted, y = AVG_PLAYING_TIME)) +
  geom_point(alpha = 0.6) +  
  geom_smooth(method="lm", color="blue", se=FALSE) +
  labs(title = "Playing Time vs. Avg Strikeouts Batted",
       x = "Average Strikeouts Batted",
       y = "Playing Time") +
  theme_minimal()

plot3 + plot4
```

```{r, fig.width=10, fig.height=5, echo=FALSE, message=FALSE}
pitching2 <- selectedVars %>% 
  filter(atBatsFaced_pitched > 100) %>% 
  mutate(
    pitcherIndicator = ifelse(total_at_bats_faced_as_starter_pitched > total_at_bats_faced_as_reliever_pitched, "Starter", "Reliever")
  ) %>%
  mutate(pitcherIndicator = factor(pitcherIndicator, levels = c("Starter", "Reliever")))

plot5 <- ggplot(pitching2, aes(x = weighted_avg_max_pitches_thrown_pitched, y = AVG_PLAYING_TIME)) +
  geom_point(aes(color = pitcherIndicator), alpha = 0.6) +  
  geom_smooth(method = "loess", color = "blue", se = FALSE) +
  labs(
    title = "Playing Time vs. Avg Max Pitches Thrown",
    x = "Avg Max Pitches Thrown",
    y = "Playing Time",
    color = "Pitcher Type" # This sets the legend title
  ) +
  scale_color_manual(values = c("Starter" = "red", "Reliever" = "blue")) +
  theme_minimal()

plot5
```


## Discussion & Limitations

> discuss submission qualifications/procedures? what else did we struggle with or could be improved upon?

## Appendix

> Our code can be accessed in this GitHub repository: https://github.com/WillPaz16/redsHackathon2025.git.
